{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ccf67-9be7-4c4f-aaee-986dc4605b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130abd15-95e7-44b9-84c4-f1a64a751cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"output/**/*summary.json\", recursive=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634ce06-d6ac-4fe3-b5bc-e1c5b3b437ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        json_data['tp'] = 1\n",
    "        if re.search(r'tp(\\d+)', file):\n",
    "            json_data['tp'] = int(re.search(r'tp(\\d+)', file).group(1))\n",
    "        json_data['file'] = file\n",
    "\n",
    "        data.append(json_data)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values(['engine', 'tp', 'dtype', 'num_concurrent_requests'])\n",
    "df.to_csv('llm_load_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182a51e-65ab-4456-803d-af50de706f09",
   "metadata": {},
   "source": [
    "TP = 1\n",
    "- mean tput per request\n",
    "- p95 ttft\n",
    "- p95 tpop\n",
    "- e2e latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2e39e-c407-4b96-a951-1cbeb8195c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.engine.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6bd95-8d1e-4f72-bdd7-614e3e2a2896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.query(\"tp == 4 and engine in ['trtllm', 'vllm'] and dtype == 'bf16'\")[['engine', 'num_concurrent_requests', 'results_request_output_throughput_token_per_s_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90357793-1e39-4ae0-9d98-6a375dd2dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "tp_size = 4\n",
    "\n",
    "metrics = [\n",
    "    \"results_request_output_throughput_token_per_s_mean\", \n",
    "    \"results_inter_token_latency_s_quantiles_p95\",\n",
    "    \"results_ttft_s_quantiles_p95\", \n",
    "    # \"results_mean_output_throughput_token_per_s\"\n",
    "    \"results_end_to_end_latency_s_quantiles_p95\",\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"Mean throughput vs Concurrency\",\n",
    "    \"Inter-token Latency (p95) vs Concurrency\",\n",
    "    \"TTFT (p95) vs Concurrency\",\n",
    "    # \"Mean total throughput vs Concurrency\"\n",
    "    \"End-to-End Latency (p95) vs Concurrency\"\n",
    "]\n",
    "\n",
    "y_labels = [\n",
    "    \"Throughput (tokens/s)\",\n",
    "    \"Inter-token Latency (s)\",\n",
    "    \"TTFT (s)\",\n",
    "    # \"Throughput (tokens/s)\"\n",
    "    \"End-to-End Latency\"\n",
    "]\n",
    "\n",
    "thresholds = {\n",
    "    \"results_request_output_throughput_token_per_s_mean\": 40,\n",
    "    \"results_inter_token_latency_s_quantiles_p95\": 0.025,\n",
    "    \"results_ttft_s_quantiles_p95\": 0.2\n",
    "}\n",
    "\n",
    "for i, (metric, title, y_label) in enumerate(zip(metrics, titles, y_labels), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    \n",
    "    for engine in df[\"engine\"].unique():\n",
    "        subset = df.query(\"tp == @tp_size and engine == @engine\").copy()\n",
    "        subset_bf16 = subset.query(\"dtype=='bf16'\")\n",
    "        subset_fp8 = subset.query(\"dtype=='fp8'\")\n",
    "\n",
    "        bf16_line, = plt.plot(subset_bf16[\"num_concurrent_requests\"], subset_bf16[metric], marker='o', label=f\"engine={engine}, dtype=bf16\")\n",
    "\n",
    "        if len(subset_fp8):\n",
    "            fp8_line, = plt.plot(subset_fp8[\"num_concurrent_requests\"], subset_fp8[metric], marker='o', label=f\"engine={engine}, dtype=fp8\")\n",
    "\n",
    "    \n",
    "    # Add horizontal threshold lines\n",
    "    if metric in thresholds:\n",
    "        plt.axhline(y=thresholds[metric], color='r', linestyle='--', \n",
    "                   label=f\"Threshold: {thresholds[metric]}\" + (\" tokens/s\" if metric == metrics[0] else \" s\"))\n",
    "    \n",
    "    plt.xlabel(\"Number of Concurrent Requests\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.title(f\"TP={tp_size}, {title}\")\n",
    "\n",
    "    if metric in ['results_inter_token_latency_s_quantiles_p95', 'results_ttft_s_quantiles_p95', 'results_end_to_end_latency_s_quantiles_p95']:\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    \n",
    "    plt.legend(title=\"Engine and dtype\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'tp{tp_size}_comparisons.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59dd1a-898f-4830-8c9f-af97a9947dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.results_request_output_throughput_token_per_s_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75cd2f-1ca5-48dc-8649-17ff83a666d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "metrics = [\n",
    "    \"results_request_output_throughput_token_per_s_mean\", \n",
    "    \"results_inter_token_latency_s_quantiles_p95\",\n",
    "    \"results_ttft_s_quantiles_p95\", \n",
    "    # \"results_end_to_end_latency_s_quantiles_p95\"\n",
    "    \"results_mean_output_throughput_token_per_s\"\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"Throughput vs Concurrency\",\n",
    "    \"Inter-token Latency (p95) vs Concurrency\",\n",
    "    \"TTFT (p95) vs Concurrency\",\n",
    "    # \"End-to-End Latency (p95) vs Concurrency\"\n",
    "    \"Mean total throughput vs Concurrency\"\n",
    "]\n",
    "\n",
    "y_labels = [\n",
    "    \"Throughput (tokens/s)\",\n",
    "    \"Inter-token Latency (s)\",\n",
    "    \"TTFT (s)\",\n",
    "    # \"End-to-End Latency (s)\"\n",
    "    \"Throughput (tokens/s)\"\n",
    "]\n",
    "\n",
    "thresholds = {\n",
    "    \"results_request_output_throughput_token_per_s_mean\": 40,\n",
    "    \"results_inter_token_latency_s_quantiles_p95\": 0.025,\n",
    "    \"results_ttft_s_quantiles_p95\": 0.2\n",
    "}\n",
    "\n",
    "for i, (metric, title, y_label) in enumerate(zip(metrics, titles, y_labels), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    \n",
    "    for tp in df[\"tp\"].unique():\n",
    "        subset = df.query(\"engine == 'vllm' and tp == @tp\").copy()\n",
    "        subset_bf16 = subset.query(\"dtype=='bf16'\")\n",
    "\n",
    "        plt.plot(subset_bf16[\"num_concurrent_requests\"], subset_bf16[metric], marker='o', label=f\"TP={tp}, dtype=bf16\")\n",
    "\n",
    "    # Add horizontal threshold lines\n",
    "    if metric in thresholds:\n",
    "        plt.axhline(y=thresholds[metric], color='r', linestyle='--', \n",
    "                   label=f\"Threshold: {thresholds[metric]}\" + (\" tokens/s\" if metric == metrics[0] else \" s\"))\n",
    "\n",
    "    plt.xlabel(\"Number of Concurrent Requests\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.title(f\"vLLM {title}\")\n",
    "\n",
    "    if metric in ['results_inter_token_latency_s_quantiles_p95', 'results_ttft_s_quantiles_p95', 'results_end_to_end_latency_s_quantiles_p95']:\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    \n",
    "    plt.legend(title=\"Engine and dtype\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('vllm_comparisons.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1e6b6-6dbe-4744-bf7c-2a3863fe995f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e35fbf-e522-40a0-b02f-c3b11176a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"engine=='trtllm_lookahead'\")[['num_concurrent_requests'] + metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81a270-7b3d-47f8-87f5-e34df1c433a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df.columns if 'number_input_tokens' in c or 'number_output_tokens' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c10d2c-7bbe-4732-ac7e-763f8d457789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
